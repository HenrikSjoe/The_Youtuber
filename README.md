# ğŸ¥ The Youtuber - RAG Chatbot

A Retrieval-Augmented Generation (RAG) chatbot that enables users to ask questions about data engineering video tutorials. Built with PydanticAI, FastAPI, LanceDB, and Streamlit.

## ğŸ“‹ Project Overview

This project creates an AI-powered assistant that answers questions based on video transcripts from data engineering tutorials. The chatbot uses vector search to find relevant content and generates educational responses using Google's Gemini model.

**Topics covered in the knowledge base:**
- SQL Analytics with DuckDB
- Python fundamentals & OOP
- FastAPI & API development
- Modern data stack (dbt, dlt, Docker)
- Pydantic & PydanticAI
- Machine Learning (Logistic Regression, XGBoost)
- Azure & Cloud deployment
- And more!

## ğŸ—ï¸ Architecture

```
User Question
     â†“
[Streamlit Frontend] â†’ [FastAPI Backend] â†’ [PydanticAI Agent]
                                                 â†“
                                          [LanceDB Vector DB]
                                                 â†“
                                          [Video Transcripts]
                                                 â†“
                                          [Gemini 2.5 Flash]
                                                 â†“
                                            Response
```

## ğŸš€ Getting Started

### Prerequisites

- Python 3.11+
- [uv](https://github.com/astral-sh/uv) package manager
- Google Gemini API key

### Installation

1. **Clone the repository**
   ```bash
   git clone https://github.com/HenrikSjoe/The_Youtuber.git
   cd The_Youtuber
   ```

2. **Install dependencies**
   ```bash
   uv sync
   ```

3. **Set up environment variables**

   Create a `.env` file in the root directory:
   ```bash
   GOOGLE_API_KEY=your_google_api_key_here
   ```

4. **Run data ingestion** (First time only)
   ```bash
   uv run python ingestion.py
   ```

   This will:
   - Create a LanceDB vector database
   - Process all video transcripts
   - Generate embeddings using Google's Gemini embedding model
   - Takes ~10 minutes due to API rate limits

### Running the Application

1. **Start the FastAPI backend**
   ```bash
   uv run uvicorn api:app --reload
   ```
   API will be available at `http://127.0.0.1:8000`

   Interactive API docs: `http://127.0.0.1:8000/docs`

2. **Start the Streamlit frontend** (in a new terminal)
   ```bash
   uv run streamlit run frontend/app.py
   ```
   Frontend will open automatically at `http://localhost:8501`

## ğŸ“¸ Screenshots

### Streamlit Interface
![Streamlit Frontend](assets/streamlit_demo.png)
*Ask questions about data engineering topics*

### API Documentation
![FastAPI Docs](assets/api_docs.png)
*Interactive API documentation with Swagger UI*

### Example Query
**Question:** "Tell me about OOP"

**Response:**
> Object-Oriented Programming (OOP) in Python revolves around classes, which act as blueprints for creating instances or objects. When you instantiate a class, the `__init__` method runs first, allowing you to define initial attributes for your object...
>
> **Source Video:** Python_oop_1

## ğŸ“ Project Structure

```
The_Youtuber/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ constants.py        # Path configurations
â”‚   â”œâ”€â”€ data_models.py      # Pydantic models
â”‚   â””â”€â”€ rag.py             # RAG agent logic
â”œâ”€â”€ data/                   # Video transcript files (.md)
â”œâ”€â”€ frontend/
â”‚   â””â”€â”€ app.py             # Streamlit UI
â”œâ”€â”€ knowledge_base/         # LanceDB vector database
â”œâ”€â”€ api.py                 # FastAPI endpoints
â”œâ”€â”€ ingestion.py           # Data ingestion script
â”œâ”€â”€ .env                   # Environment variables
â”œâ”€â”€ pyproject.toml         # Project dependencies
â””â”€â”€ README.md
```

## ğŸ› ï¸ Technologies Used

- **PydanticAI**: AI agent framework with structured outputs
- **FastAPI**: High-performance API framework
- **Streamlit**: Interactive web frontend
- **LanceDB**: Vector database for embeddings
- **Google Gemini**: LLM and embedding model
- **Python 3.11**: Core programming language
- **uv**: Fast Python package manager

## ğŸ”§ API Endpoints

### `GET /`
Health check and API information

### `POST /rag/query`
Query the RAG chatbot

**Request Body:**
```json
{
  "prompt": "How do I setup DuckDB?"
}
```

**Response:**
```json
{
  "video_title": "SQL analytics course with DuckDB - setup duckdb",
  "filepath": "/path/to/transcript.md",
  "answer": "Detailed answer based on video content..."
}
```

## ğŸ“š Key Features

- âœ… Vector-based semantic search
- âœ… Context-aware responses
- âœ… Source attribution (cites video sources)
- âœ… Educational tone matching The Youtuber's style
- âœ… Fast retrieval with LanceDB
- âœ… Interactive web interface
- âœ… RESTful API

## ğŸ§ª Example Queries

Try asking:
- "How do I setup DuckDB?"
- "Explain Python OOP concepts"
- "What is FastAPI?"
- "How do I use Pydantic?"
- "Tell me about Docker"

## ğŸ“ Notes

- First-time ingestion takes ~10 minutes due to Google API rate limits
- The system uses `gemini-2.5-flash` for generation and `gemini-embedding-001` for embeddings
- Responses are limited to 6 sentences for clarity

## ğŸ“„ License

This project is for educational purposes as part of an AI Engineering course.
